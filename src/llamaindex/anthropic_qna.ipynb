{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujkafp8Nmc-U"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -qU llama-index\n",
    "!pip install -qU weave ml-collections\n",
    "!pip install -qU llama-index-llms-anthropic\n",
    "!pip install -qU llama-index-callbacks-wandb\n",
    "!git clone https://github.com/wandb/weave.git\n",
    "!pip install -qU llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "import weave\n",
    "from google.colab import userdata\n",
    "from llama_index.callbacks.wandb import WandbCallbackHandler\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"W&B\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "weave.init(\"chatbot-claude3-llamaindex-weave\")\n",
    "wandb_callback = WandbCallbackHandler(\n",
    "    run_args={\"project\": \"chatbot-claude3-llamaindex-weave\"}\n",
    ")"
   ],
   "metadata": {
    "id": "13bn7IHRoDCc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title ‚öôÔ∏è Configuration\n",
    "import ml_collections\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "def get_config() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.model: str = \"claude-3-haiku-20240307\"  # @param {type: \"string\"}\n",
    "    config.embedding_model: str = \"BAAI/bge-small-en-v1.5\"  # @param {type: \"string\"}\n",
    "    config.fetch_index_from_wandb: bool = True  # @param {type: \"boolean\"}\n",
    "    return config\n",
    "\n",
    "\n",
    "config = get_config()"
   ],
   "metadata": {
    "id": "v8u5Cv4OoNI3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üíø The Dataset\n",
    "---"
   ],
   "metadata": {
    "id": "UVitEuC4qCVi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "required_exts = [\".md\"]\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=\"/content/weave/docs\",\n",
    "    required_exts=required_exts,\n",
    "    recursive=True,\n",
    ")\n",
    "\n",
    "docs = reader.load_data()"
   ],
   "metadata": {
    "id": "uV_GLDsd6OpN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ‚úçÔ∏è Model Architecture & Training\n",
    "---"
   ],
   "metadata": {
    "id": "PUbMx8pwqG5q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "%%capture\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "\n",
    "Settings.llm = Anthropic(temperature=0.0, model=config.model)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=config.embedding_model)"
   ],
   "metadata": {
    "id": "BQyvv1DmqJdV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üóÇ Creating a Index\n",
    "---"
   ],
   "metadata": {
    "id": "q9w25-IDwLuL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "if not config.fetch_index_from_wandb:\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    wandb_callback.persist_index(index, index_name=\"claude3-index\")"
   ],
   "metadata": {
    "id": "-WN-MZttqkhS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "if config.fetch_index_from_wandb:\n",
    "    storage_context = wandb_callback.load_storage_context(\n",
    "        artifact_url=\"sauravmaheshkar/chatbot-claude3-llamaindex-weave/claude3-index:v0\"\n",
    "    )\n",
    "\n",
    "    # Load the index and initialize a query engine\n",
    "    index = load_index_from_storage(\n",
    "        storage_context,\n",
    "    )"
   ],
   "metadata": {
    "id": "wwy34ahvqvuc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What python version does weave require ?\")\n",
    "print(response, sep=\"\\n\")"
   ],
   "metadata": {
    "id": "55lJ2BIeq0SE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb_callback.finish()"
   ],
   "metadata": {
    "id": "JeVaIOMuq3MW"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
